{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certificate in AI Study Guide\n",
    "=============================\n",
    "\n",
    "Scientific Computing\n",
    "--------------------\n",
    "\n",
    "### Equations\n",
    "\n",
    "* Derivatives\n",
    "* Partial Derivatives\n",
    "\n",
    "### Matrices\n",
    "\n",
    "#### Addition\n",
    "#### Substraction\n",
    "#### Multiplication\n",
    "#### Dot-Product\n",
    "#### Cross-Product\n",
    "#### Determinant\n",
    "[Determinant](https://en.wikipedia.org/wiki/Determinant): In linear algebra, the *determinant* is a value that can be computed from the elements of a square matrix. The determinant of a matrix A is denoted det(A), det A, or |A|. Geometrically, it can be viewed as the scaling factor of the linear transformation described by the matrix.<br/> ![2x2 Matrix Determinant](https://wikimedia.org/api/rest_v1/media/math/render/svg/5b2e40d390e1d26039aabee44c7d1d86c8755232) <br/> ![3X3 Matrix Determinant](https://wikimedia.org/api/rest_v1/media/math/render/svg/14f2f2a449d6d152ee71261e47551aa0a31c801e)\n",
    "#### Vector\n",
    "#### Transpose\n",
    "#### Inverse\n",
    "\n",
    "### Linear Algebra\n",
    "\n",
    "* Principal Components Analysis (PCA)\n",
    "* Eigen Vectors / Eigen Values\n",
    "\n",
    "\n",
    "### Probabilities\n",
    "\n",
    "* Random\n",
    "* Distribution\n",
    "* Visualisation/Plots\n",
    "\n",
    "\n",
    "Deep Neural Network\n",
    "-------------------\n",
    "\n",
    "### Theory\n",
    "\n",
    "* Activation\n",
    "* Bias\n",
    "* Weights\n",
    "* Nodes/Kernels\n",
    "* Forward / Bacward Propagation\n",
    "* **Epochs**: In a configured neural network model that can be trained, the number of epoch needs to be specified. Each epoch corresponds to one complete forward and backward propogation of the neural network (with the weights at each neuron being updated during back propogation).\n",
    "\n",
    "* Max-Pooling\n",
    "* Training and Test Sets\n",
    "* Dropout Layer\n",
    "* Mini-batch\n",
    "* Sigmoid/ReLU/Softmax\n",
    "\n",
    "### Various Neural Network\n",
    "\n",
    "https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/\n",
    "\n",
    "* Regression / Classification\n",
    "* RBM\n",
    "* ANN\n",
    "* **RNN**: One restriction of a Restricted Boltzmann Machine (RBM), is that the nodes within a layer do not connect to each other.\n",
    "A RNN breaks this rule by allowing to connect nodes from the same layer, allowing for dependencies between inputs.\n",
    "This makes the RNN suitable for timeseries or sequential data. \n",
    "* CNN\n",
    "* GAN\n",
    "* Autoencoder\n",
    "* Decision trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
